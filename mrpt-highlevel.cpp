//Code by Max Henner Gerlach, 2010--2012,
//used for the diploma thesis "Directional Ordering in the Classical Compass Model in Two and Three Dimensions"
//contact: maxgerlach@gmail.com

/*
 * mrpt-highlevel.cpp
 *
 *  Created on: Aug 5, 2011
 *      Author: max
 */

// generalized for SDW DQMC (2015-02-06 - )

#include <iostream>
#include <fstream>
#include <exception>
#include <map>
#include <string>
#include "metadata.h"
#include "tools.h"
#include "datamapwriter.h"
#include "dlib/cmd_line_parser.h"
#include "mrpt.h"
#include "mrpt-jk.h"
#include "mrpt-highlevel.h"

using namespace std;

//variables in the following anonymous namespace are local to this file
namespace {
    MultireweightHistosPT* mr = 0;

    unsigned binCount = 0;
    bool discreteIsingBins = false;

    bool use_jackknife = false;
    unsigned jackknifeBlocks = 0;

    bool do_directEstimates = false;

    bool non_iterative = true;
    unsigned maxIterations = 10000;
    double iterationTolerance = 1E-7;

    bool be_quiet = false;
    ofstream dev_null("/dev/null");
    string outputDirPrefix;
    string infoFilename;

    typedef dlib::cmd_line_parser<char>::check_1a_c clp;
    clp parser;

    unsigned subsample = 1;
    unsigned discardSamples = 0;
    bool sortByBeta = false;
    bool saveTauInt = false;
    string zInFile;
    string zOutFile;

    bool globalTau = false;
    bool noTau = false;
    bool autocorrPlots = false;
    bool crossCorr = false;
    bool crossCorrAlt = false;

    string headerSuffix;

}



void initFromCommandLine(int argc, char** argv) {
    //Command line parsing
    parser.add_option("help", "display this help message");
    parser.add_option("q", "be less verbose");
    parser.add_option("info", "info generated by simulation (\"info.dat\")", 1);
    parser.add_option("b", "number of energy bins", 1);
    parser.add_option("discrete-ising-bins", "Pass this instead of -b to set up energy bins that match the natural discrete energies of the 2D Ising model of this system size.");
    parser.add_option("i", "max number of iterations to determine Z[beta]", 1);
    parser.add_option("t", "tolerance in iterative determination of Z[beta]", 1);
    parser.add_option("loadz", "load partition functions from the indicated file", 1);
    parser.add_option("savez", "save partition functions to the indicated file", 1);

    parser.add_option("direct", "also calculate direct averages from the time series at the original temperatures without any reweighting");

    parser.add_option("non-iterative", "first do a non-iterative estimation of the density of states as in Fenwick, 2008");

    parser.add_option("constant-overlap", "iteratively reweight energy histograms until constant overlap is achieved");
    parser.add_option("n", "indicates number of target temperatures if --constant-overlap is passed. Default: same as input.", 1);

    parser.add_option("beta-range", "Takes three arguments to determine the range of inverse temperatures to reweight to: the minimum, the maximum and the step size", 3);
    parser.add_option("beta-range-discrete", "Takes three arguments to determine the range of inverse temperatures to discretely reweight energy and heat capacity to: the minimum, the maximum and the step size", 3);
    parser.add_option("j", "use jack-knife error estimation, indicate number of blocks", 1);
    parser.add_option("h", "write reweighted histograms at each target beta");

    parser.add_option("max-susc", "Search the maximum of the observable susceptibiliy between the inverse temperatures given as arguments", 2);
    parser.add_option("min-binder", "Search the minimum of the binder cumulant of the observable between the inverse temperatures given as arguments", 2);
    parser.add_option("max-specific-heat", "Search the maximum of the specific heat between the inverse temperatures given as arguments", 2);
    parser.add_option("energy-double-peak", "Search equal-height and equal-weight double-peak energy histograms between the inverse temperatures given as arguments", 2);
    parser.add_option("obs-double-peak", "Search an equal-height and equal-weight double-peak observable histograms between the inverse temperatures given as arguments", 2);
    parser.add_option("peak-tolerance", "tolerance factor in determining dip in double-peak histograms. Default: 0.1", 1);

    parser.add_option("reldip-at", "Determine relative dips in histograms at given target beta", 1);

    parser.add_option("sub-sample", "Sub samples the time series as they are read in (pass number of data points to be put into one sample", 1);
    parser.add_option("d", "Discard the first samples of the time series (pass number of samples to be left out) -- allows for further thermalization.", 1);
    parser.add_option("sort", "Sort replica timeseries by temperatures before doing any processing (simulate canonical data). This could hide correlations.");
    parser.add_option("save-tau-int", "Estimate and write out integrated autocorrelation times. Requires --sort");

    parser.add_option("global-tau", "Do not estimate statistical inefficiencies for individual bins, but only globally for each temperature -- g_km = g_k");
    parser.add_option("no-tau", "Ignore all differences in statistical inefficiencies when reweighting -- g_km = 1");

    parser.add_option("cross-corr", "Calculate (histogram bin) cross-correlation coefficients for H_km, H_kn");
    parser.add_option("cross-corr-alt", "Calculate (histogram bin) cross-correlation coefficients for H_km, H_kn using an alternative method (probably slow and bad)");

    parser.add_option("autocorr-plots", "Write out the data points used to estimate (bin) statistical inefficiencies to check the form of the auto-correlation functions");

    //further general arguments: file names of energy/observable time series
    parser.parse(argc, argv);

    //echo whole commandline:
    cout << "command line: ";
    for (int arg = 0; arg < argc; ++arg) {
        cout << argv[arg] << " ";
    }
    cout << endl;

    const char* one_time_opts[] = {"info", "b", "loadz", "savez", "n", "beta-range", "j", "i", "sub-sample", "sort"};
    parser.check_one_time_options(one_time_opts);
    const char* incompatible[] = {"constant-overlap", "beta-range"};
    parser.check_incompatible_options(incompatible);
    const char* incompatible1[] = {"global-tau", "no-tau"};
    parser.check_incompatible_options(incompatible1);
    const char* incompatible2[] = {"autocorr-plots", "no-tau"};
    parser.check_incompatible_options(incompatible2);
    const char* incompatible3[] = {"b", "discrete-ising-bins"};
    parser.check_incompatible_options(incompatible3);

    if (parser.option("help")) {
        cout << "Multihistogram reweighting for time series originating from parallel tempering or canonical simulations" << endl;
        cout << "Command line options understood:" << endl;
        parser.print_options(cout);
        cout << endl;
        return;
    }

    if (const clp::option_type& jk = parser.option("j")) {
        setJackknife(true, fromString<unsigned>(jk.argument()));
    }

    be_quiet = parser.option("q");
    infoFilename = (parser.option("info") ?
            parser.option("info").argument() : "info.dat");

    if (not parser.option("b")) {
        if (parser.option("discrete-ising-bins")) {
            discreteIsingBins = true;
        } else {
            cerr << "energy bin count not specified (option -b)!" << endl;
        }
    } else {
        binCount = dlib::sa = parser.option("b").argument();
    }

    do_directEstimates = parser.option("direct");

    non_iterative = parser.option("non-iterative");
    maxIterations = (non_iterative ? 0 : 10000);            //if non-iterative estimation is attempted, by default don't do any iterations, else default to 1000
    if (parser.option("i")) {
        maxIterations = dlib::sa = parser.option("i").argument();
    }
    if (parser.option("t")) {
        iterationTolerance = dlib::sa = parser.option("t").argument();
    }

    bool createHistograms = parser.option("h");

    if (const clp::option_type& ss = parser.option("sub-sample")) {
        subsample = dlib::sa = ss.argument();
    }

    if (const clp::option_type& dd = parser.option("d")) {
        discardSamples = dlib::sa = dd.argument();
    }

    sortByBeta = parser.option("sort");
    saveTauInt = sortByBeta and parser.option("save-tau-int");
    zInFile  = (parser.option("loadz") ? parser.option("loadz").argument() : "");
    zOutFile = (parser.option("savez") ? parser.option("savez").argument() : "");

    globalTau = parser.option("global-tau");
    noTau = parser.option("no-tau");
    autocorrPlots = parser.option("autocorr-plots");
    crossCorr = parser.option("cross-corr");
    crossCorrAlt = parser.option("cross-corr-alt");

    init();

    if (const clp::option_type& rr = parser.option("beta-range")) {
        double betaMin = dlib::sa = rr.argument(0);
        double betaMax = dlib::sa = rr.argument(1);
        double betaStep = dlib::sa = rr.argument(2);
        reweightRange(betaMin, betaMax, betaStep, createHistograms);
    }

    if (const clp::option_type& rr = parser.option("beta-range-discrete")) {
        double betaMin = dlib::sa = rr.argument(0);
        double betaMax = dlib::sa = rr.argument(1);
        double betaStep = dlib::sa = rr.argument(2);
        reweightDiscreteRange(betaMin, betaMax, betaStep, createHistograms);
    }

    if (parser.option("constant-overlap")) {
        int targetNumBetas = 0;                 //0 or specified
        if (const clp::option_type& nOption = parser.option("n")) {
            targetNumBetas = dlib::sa = nOption.argument();
        }
        reweightConstantOverlap(targetNumBetas);
    }

    if (const clp::option_type& fms = parser.option("max-susc")) {
        double findMaxSuscBetaStart = dlib::sa = fms.argument(0);
        double findMaxSuscBetaEnd = dlib::sa = fms.argument(1);
        findMaxSusc(findMaxSuscBetaStart, findMaxSuscBetaEnd);
    }

    if (const clp::option_type& fms = parser.option("min-binder")) {
        double findMinBinderBetaStart = dlib::sa = fms.argument(0);
        double findMinBinderBetaEnd = dlib::sa = fms.argument(1);
        findMinBinder(findMinBinderBetaStart, findMinBinderBetaEnd);
    }

    if (const clp::option_type& fms = parser.option("max-specific-heat")) {
        double findMaxSpecificHeatBetaStart = dlib::sa = fms.argument(0);
        double findMaxSpecificHeatBetaEnd = dlib::sa = fms.argument(1);
        findMaxSpecificHeat(findMaxSpecificHeatBetaStart, findMaxSpecificHeatBetaEnd);
    }

    double peakTolerance = .05;
    if (const clp::option_type& pt = parser.option("peak-tolerance")) {
        peakTolerance = dlib::sa = pt.argument(0);
    }

    if (const clp::option_type& dp = parser.option("energy-double-peak")) {
        double betaStart = dlib::sa = dp.argument(0);
        double betaEnd = dlib::sa = dp.argument(1);
        findEnergyDoublePeak(betaStart, betaEnd, peakTolerance);
    }

    if (const clp::option_type& dp = parser.option("obs-double-peak")) {
        double betaStart = dlib::sa = dp.argument(0);
        double betaEnd = dlib::sa = dp.argument(1);
        findObservableDoublePeak(betaStart, betaEnd, peakTolerance);
    }

    if (const clp::option_type& rda = parser.option("reldip-at")) {
        double targetBeta = dlib::sa = rda.argument(0);
        findEnergyRelDip(targetBeta, peakTolerance);
        findObservableRelDip(targetBeta, peakTolerance);
    }
}


//maps beta->observable (or function there of, their errors)
//reset in init(), afterwards grow after various reweighting calls
typedef map<double, double> Map;
//results from multi-histogram reweighting:
Map energy;
Map specificHeat;
Map observable;
Map susceptibility;
Map binder;
Map energyError;
Map specificHeatError;
Map observableError;
Map susceptibilityError;
Map binderError;
//results from direct averaging of time series sorted by temperature:
Map direct_energy;
Map direct_specificHeat;
Map direct_observable;
Map direct_susceptibility;
Map direct_binder;
Map direct_energyError;
Map direct_specificHeatError;
Map direct_observableError;
Map direct_susceptibilityError;
Map direct_binderError;

//internal function to output the above maps
void writeOutResults() {
    //reweighting results:
    if (not energy.empty()) {
        DoubleMapWriter energyOut;
        energyOut.setData(&energy);
        if (use_jackknife) energyOut.setErrors(&energyError);
        energyOut.addHeaderText("MRPT estimates of energy");
        if (use_jackknife) energyOut.addHeaderText("jackknife error estimation");
        energyOut.addMeta("energyBins", binCount);
        energyOut.addMeta("observable", "energy");
        energyOut.addMeta("L", mr->getSystemL());
        energyOut.addMeta("N", mr->getSystemN());
        if (use_jackknife) energyOut.addMeta("jackknifeBlockcount", jackknifeBlocks);
        energyOut.addHeaderText("beta\t energy" + headerSuffix);
        energyOut.writeToFile(outputDirPrefix + "mrpt-energy-l-" + numToString(mr->getSystemL()) + ".values");
    }

    if (not specificHeat.empty()) {
        DoubleMapWriter specificHeatOut;
        specificHeatOut.setData(&specificHeat);
        if (use_jackknife) specificHeatOut.setErrors(&specificHeatError);
        specificHeatOut.addHeaderText("MRPT estimates of specific heat");
        if (use_jackknife) specificHeatOut.addHeaderText("jackknife error estimation");
        specificHeatOut.addMeta("energyBins", binCount);

        specificHeatOut.addMeta("observable", "energy");
        specificHeatOut.addMeta("L", mr->getSystemL());
        specificHeatOut.addMeta("N", mr->getSystemN());
        if (use_jackknife) specificHeatOut.addMeta("jackknifeBlockcount", jackknifeBlocks);
        specificHeatOut.addHeaderText("beta\t specificHeat" + headerSuffix);
        specificHeatOut.writeToFile(outputDirPrefix + "mrpt-specific-heat-l-" + numToString(mr->getSystemL()) + ".values");
    }

    if (not observable.empty()) {
        DoubleMapWriter observableOut;
        observableOut.setData(&observable);
        if (use_jackknife) observableOut.setErrors(&observableError);
        observableOut.addHeaderText("MRPT estimates of " + mr->getObservableName());
        if (use_jackknife) observableOut.addHeaderText("jackknife error estimation");
        observableOut.addMeta("energyBins", binCount);
        observableOut.addMeta("observable", mr->getObservableName());
        observableOut.addMeta("L", mr->getSystemL());
        observableOut.addMeta("N", mr->getSystemN());
        if (use_jackknife) observableOut.addMeta("jackknifeBlockcount", jackknifeBlocks);
        observableOut.addHeaderText("beta\t " + mr->getObservableName() + headerSuffix);
        observableOut.writeToFile(outputDirPrefix + "mrpt-" + mr->getObservableName() + "-l-" + numToString(mr->getSystemL()) + ".values");
    }

    if (not susceptibility.empty()) {
        DoubleMapWriter susceptibilityOut;
        susceptibilityOut.setData(&susceptibility);
        if (use_jackknife) susceptibilityOut.setErrors(&susceptibilityError);
        susceptibilityOut.addHeaderText("MRPT estimates of " + mr->getObservableName() + " susceptibility");
        if (use_jackknife) susceptibilityOut.addHeaderText("jackknife error estimation");
        susceptibilityOut.addMeta("energyBins", binCount);
        susceptibilityOut.addMeta("observable", mr->getObservableName());
        susceptibilityOut.addMeta("L", mr->getSystemL());
        susceptibilityOut.addMeta("N", mr->getSystemN());
        if (use_jackknife) susceptibilityOut.addMeta("jackknifeBlockcount", jackknifeBlocks);
        susceptibilityOut.addHeaderText("beta\t susc" + headerSuffix);
        susceptibilityOut.writeToFile(outputDirPrefix + "mrpt-susc-" + mr->getObservableName() + "-l-" + numToString(mr->getSystemL()) + ".values");
    }

    if (not binder.empty()) {
        DoubleMapWriter binderOut;
        binderOut.setData(&binder);
        if (use_jackknife) binderOut.setErrors(&binderError);
        binderOut.addHeaderText("MRPT estimates of " + mr->getObservableName() + " binder parameter");
        if (use_jackknife) binderOut.addHeaderText("jackknife error estimation");
        binderOut.addMeta("energyBins", binCount);
        binderOut.addMeta("observable", mr->getObservableName());
        binderOut.addMeta("L", mr->getSystemL());
        binderOut.addMeta("N", mr->getSystemN());
        if (use_jackknife) binderOut.addMeta("jackknifeBlockcount", jackknifeBlocks);
        binderOut.addHeaderText("beta\t susc" + headerSuffix);
        binderOut.writeToFile(outputDirPrefix + "mrpt-binder-" + mr->getObservableName() + "-l-" + numToString(mr->getSystemL()) + ".values");
    }

    //results from direct averaging:
    if (not direct_energy.empty()) {
        DoubleMapWriter energyOut;
        energyOut.setData(&direct_energy);
        if (use_jackknife) energyOut.setErrors(&direct_energyError);
        energyOut.addHeaderText("Direct estimates of energy");
        if (use_jackknife) energyOut.addHeaderText("jackknife error estimation");
        energyOut.addMeta("observable", "energy");
        energyOut.addMeta("L", mr->getSystemL());
        energyOut.addMeta("N", mr->getSystemN());
        if (use_jackknife) energyOut.addMeta("jackknifeBlockcount", jackknifeBlocks);
        energyOut.addHeaderText("beta\t energy" + headerSuffix);
        energyOut.writeToFile(outputDirPrefix + "mrpt-direct-energy-l-" + numToString(mr->getSystemL()) + ".values");
    }

    if (not direct_specificHeat.empty()) {
        DoubleMapWriter specificHeatOut;
        specificHeatOut.setData(&direct_specificHeat);
        if (use_jackknife) specificHeatOut.setErrors(&direct_specificHeatError);
        specificHeatOut.addHeaderText("Direct estimates of specific heat");
        if (use_jackknife) specificHeatOut.addHeaderText("jackknife error estimation");
        specificHeatOut.addMeta("observable", "energy");
        specificHeatOut.addMeta("L", mr->getSystemL());
        specificHeatOut.addMeta("N", mr->getSystemN());
        if (use_jackknife) specificHeatOut.addMeta("jackknifeBlockcount", jackknifeBlocks);
        specificHeatOut.addHeaderText("beta\t specificHeat" + headerSuffix);
        specificHeatOut.writeToFile(outputDirPrefix + "mrpt-direct-specific-heat-l-" + numToString(mr->getSystemL()) + ".values");
    }

    if (not direct_observable.empty()) {
        DoubleMapWriter observableOut;
        observableOut.setData(&direct_observable);
        if (use_jackknife) observableOut.setErrors(&direct_observableError);
        observableOut.addHeaderText("Direct estimates of " + mr->getObservableName());
        if (use_jackknife) observableOut.addHeaderText("jackknife error estimation");
        observableOut.addMeta("observable", mr->getObservableName());
        observableOut.addMeta("L", mr->getSystemL());
        observableOut.addMeta("N", mr->getSystemN());
        if (use_jackknife) observableOut.addMeta("jackknifeBlockcount", jackknifeBlocks);
        observableOut.addHeaderText("beta\t " + mr->getObservableName() + headerSuffix);
        observableOut.writeToFile(outputDirPrefix + "mrpt-direct-" + mr->getObservableName() + "-l-" + numToString(mr->getSystemL()) + ".values");
    }

    if (not direct_susceptibility.empty()) {
        DoubleMapWriter susceptibilityOut;
        susceptibilityOut.setData(&direct_susceptibility);
        if (use_jackknife) susceptibilityOut.setErrors(&direct_susceptibilityError);
        susceptibilityOut.addHeaderText("Direct estimates of " + mr->getObservableName() + " susceptibility");
        if (use_jackknife) susceptibilityOut.addHeaderText("jackknife error estimation");
        susceptibilityOut.addMeta("observable", mr->getObservableName());
        susceptibilityOut.addMeta("L", mr->getSystemL());
        susceptibilityOut.addMeta("N", mr->getSystemN());
        if (use_jackknife) susceptibilityOut.addMeta("jackknifeBlockcount", jackknifeBlocks);
        susceptibilityOut.addHeaderText("beta\t susc" + headerSuffix);
        susceptibilityOut.writeToFile(outputDirPrefix + "mrpt-direct-susc-" + mr->getObservableName() + "-l-" + numToString(mr->getSystemL()) + ".values");
    }

    if (not direct_binder.empty()) {
        DoubleMapWriter binderOut;
        binderOut.setData(&direct_binder);
        if (use_jackknife) binderOut.setErrors(&direct_binderError);
        binderOut.addHeaderText("Direct estimates of " + mr->getObservableName() + " binder parameter");
        if (use_jackknife) binderOut.addHeaderText("jackknife error estimation");
        binderOut.addMeta("observable", mr->getObservableName());
        binderOut.addMeta("L", mr->getSystemL());
        binderOut.addMeta("N", mr->getSystemN());
        if (use_jackknife) binderOut.addMeta("jackknifeBlockcount", jackknifeBlocks);
        binderOut.addHeaderText("beta\t susc" + headerSuffix);
        binderOut.writeToFile(outputDirPrefix + "mrpt-direct-binder-" + mr->getObservableName() + "-l-" + numToString(mr->getSystemL()) + ".values");
    }

}

void setSubsample(unsigned samplesSize) {
    subsample = samplesSize;
}

void setOutputDirectory(const char *dir) {
    string directory = dir;
    if (directory == "") directory = ".";
    outputDirPrefix = directory + "/";
}

void setInfoFilename(const char *filename) {
    infoFilename = filename;
}

void setBins(unsigned bins) {
    binCount = bins;
}

void setJackknife(bool useJackknife, unsigned blocks) {
    use_jackknife = useJackknife;
    jackknifeBlocks = blocks;
    headerSuffix = (use_jackknife ? "\t error" : "");
}

void setQuiet(bool quiet) {
    be_quiet = quiet;
}

void setMaxIterations(unsigned max_iterations) {
    maxIterations = max_iterations;
}

void setTolerance(double tolerance) {
    iterationTolerance = tolerance;
}

void init() {
    destroy(mr);
    energy.clear();
    specificHeat.clear();
    observable.clear();
    susceptibility.clear();
    binder.clear();
    energyError.clear();
    specificHeatError.clear();
    observableError.clear();
    susceptibilityError.clear();
    binderError.clear();
    mr = (use_jackknife ?
        new MultireweightHistosPTJK(jackknifeBlocks, be_quiet ? dev_null : cout) :
        new MultireweightHistosPT(be_quiet ? dev_null : cout));

    mr->addSimulationInfo(infoFilename);

    //TODO: currently command line arguments are the only way to specify
    //input time series
    for (unsigned arg = 0; arg < parser.number_of_arguments(); ++arg) {
        mr->addInputTimeSeries(parser[arg], subsample, discardSamples);
    }

    if (sortByBeta) {
        mr->sortTimeSeriesByBeta();
    }

    if (do_directEstimates) {
        directResults();
    }

    if (discreteIsingBins) {
        mr->createHistogramsIsing();
    } else {
        mr->createHistograms(binCount);
    }
    mr->saveH_km(outputDirPrefix + "Hkm.table");

    if (crossCorr) {
        mr->computeAndSaveHistogramCrossCorr();
    }
    if (crossCorrAlt) {
        mr->computeAndSaveHistogramCrossCorrAlt();
    }

    if (use_jackknife) {
        //TODO: ugly, ugly, ugly
        dynamic_cast<MultireweightHistosPTJK*>(mr)->
                saveH_km_errors(outputDirPrefix + "Hkm-errors.table");
    }
    mr->saveU_m(outputDirPrefix + "Um.table");

    if (non_iterative) {
        mr->findDensityOfStatesNonIteratively();
    }

    if (noTau) {
        mr->setBinInefficienciesToUnity();
    } else if (globalTau) {
        mr->measureGlobalInefficiencies(autocorrPlots);
    } else {
        mr->measureBinInefficiencies(autocorrPlots);
    }

    if (saveTauInt) {
        mr->writeOutEnergyTauInt("mrpt-tauint-energy.dat");
        mr->writeOutObsTauInt("mrpt-tauint-" + mr->observable + ".dat");
    }

    mr->saveg_km(outputDirPrefix + "gkm.table");

    mr->updateEffectiveCounts();

    //those quantities are not really interesting:
//    mr->saveNeff_lm(outputDirPrefix + "Nefflm.table");
//    mr->saveNeff_l(outputDirPrefix + "Neffl.table");

    if (zInFile != "") {
        //load partition functions as starting point for iteration
        mr->loadPartitionFunctions(zInFile);
    }

    if (maxIterations > 0) {
        mr->findPartitionFunctionsAndDensityOfStates(iterationTolerance, maxIterations);
    }

    if (discreteIsingBins) {
        mr->saveLogDensityOfStatesIsing(outputDirPrefix + "mrpt-dos.dat");
    } else {
        mr->saveLogDensityOfStates(outputDirPrefix + "mrpt-dos.dat");
    }

    if (zOutFile != "") {
        mr->savePartitionFunctions(zOutFile);
    }
}

void directResults() {
    typedef MultireweightHistosPT::ResultsMap ResMap;
    ResMap* results = mr->directNoReweighting();

    for (ResMap::const_iterator iter = results->begin();
            iter != results->end(); ++iter) {
        double beta = iter->first;
        ReweightingResult values = iter->second;
        direct_energy[beta] = values.energyAvg;
        direct_specificHeat[beta] = values.heatCapacity;
        direct_observable[beta] = values.obsAvg;
        direct_susceptibility[beta] = values.obsSusc;
        direct_binder[beta] = values.obsBinder;
        if (use_jackknife) {
            direct_energyError[beta] = values.energyError;
            direct_specificHeatError[beta] = values.heatCapacityError;
            direct_observableError[beta] = values.obsError;
            direct_susceptibilityError[beta] = values.obsSuscError;
            direct_binderError[beta] = values.obsBinderError;
        }
    }

    writeOutResults();

    destroy(results);
}



//inline class somewhat like lambda function (restriction: can't access "auto" variables
//in containing function):
class ReweightAndHandle {
    bool createHistograms;
public:
    ReweightAndHandle(bool withHistograms = false) : createHistograms(withHistograms)
    { }
    void operator()(double beta) {
        ReweightingResult result = (
                createHistograms ?
                        mr->reweightWithHistograms(beta, binCount) :
                        mr->reweight(beta));
        energy[beta] = result.energyAvg;
        specificHeat[beta] = result.heatCapacity;
        observable[beta] = result.obsAvg;
        susceptibility[beta] = result.obsSusc;
        binder[beta] = result.obsBinder;
        if (use_jackknife) {
            energyError[beta] = result.energyError;
            specificHeatError[beta] = result.heatCapacityError;
            observableError[beta] = result.obsError;
            susceptibilityError[beta] = result.obsSuscError;
            binderError[beta] = result.obsBinderError;
        }
        if (createHistograms) {
            result.energyHistogram->save("mrpt-energy-b" + numToString(beta) + ".hist");
            result.obsHistogram->save("mrpt-" + mr->getObservableName() + "-b" + numToString(beta) + ".hist");
        }
        result.freeMemory();
    }
};

class ReweightAndHandleDiscrete {
    bool createHistogram;
public:
    ReweightAndHandleDiscrete(bool withHistogram = false) : createHistogram(withHistogram)
    { }
    void operator()(double beta) {
        ReweightingResult result =
                mr->reweightDiscrete(beta);
        energy[beta] = result.energyAvg;
        specificHeat[beta] = result.heatCapacity;
        if (use_jackknife) {
            energyError[beta] = result.energyError;
            specificHeatError[beta] = result.heatCapacityError;
        }
        if (createHistogram) {
            result.energyHistogram = mr->reweightEnergyHistogram(beta);
            result.energyHistogram->save("mrpt-energy-b" + numToString(beta) + ".hist");
        }
        result.freeMemory();
    }
};


void reweight(double beta, bool createHistogramsToo) {
    ReweightAndHandle reweight(createHistogramsToo);
    reweight(beta);
    writeOutResults();
}

void reweightDiscrete(double beta, bool createHistogramToo) {
    ReweightAndHandleDiscrete reweight(createHistogramToo);
    reweight(beta);
    writeOutResults();
}


void reweightEnergyHistogram(double beta) {
    HistogramDouble* histo = mr->reweightEnergyHistogram(beta);
    histo->save("mrpt-energy-b" + numToString(beta) + ".hist");
    destroy(histo);
}

void reweightObservableHistogram(double beta) {
    HistogramDouble* histo = mr->reweightObservableHistogram(beta, binCount);
    histo->save("mrpt-" + mr->getObservableName() + "-b" + numToString(beta) + ".hist");
    destroy(histo);
}


void reweightRange(double betaMin, double betaMax, double betaStep,
        bool createHistogramsToo) {
    ReweightAndHandle reweight(createHistogramsToo);
    for (double beta = betaMin; beta <= betaMax; beta += betaStep) {
        reweight(beta);
    }
    writeOutResults();
}

void reweightDiscreteRange(double betaMin, double betaMax, double betaStep, bool createHistogramsToo) {
    ReweightAndHandleDiscrete reweight(createHistogramsToo);
    for (double beta = betaMin; beta <= betaMax; beta += betaStep) {
        reweight(beta);
    }
    writeOutResults();
}


void reweightConstantOverlap(double targetNumBetas) {
    BetaRange newBetas;
    if (targetNumBetas == 0) {
        newBetas = mr->reweightToConstantEnergyOverlap(1000, 0.05);
    } else {
        newBetas = mr->reweightToConstantEnergyOverlap(targetNumBetas, 1000, 0.05);
    }
    string filename = outputDirPrefix + "mrpt-betas-constant-overlap.dat";
    if (not be_quiet) cout << "Storing final set of inverse temperatures in " << filename << endl;
    newBetas.saveBetas(filename);
}

void reweightConstantOverlap(double betaMin, double betaMax, unsigned targetNumBetas) {
    BetaRange newBetas;
    newBetas = mr->reweightToConstantEnergyOverlap(betaMin, betaMax, targetNumBetas, 1000, 0.05);
    string filename = outputDirPrefix + "mrpt-betas-constant-overlap.dat";
    if (not be_quiet) cout << "Storing final set of inverse temperatures in " << filename << endl;
    newBetas.saveBetas(filename);
}

void findMaxSusc(double betaStart, double betaEnd) {
    double betaMax;
    double suscMax;
    double betaMaxError;
    double suscMaxError;
    if (not use_jackknife) {
        mr->findMaxObservableSusceptibility(betaMax, suscMax, susceptibility, betaStart, betaEnd);
    } else {
        //TODO: store evaluated points somewhere
        vector<map<double,double> > v(jackknifeBlocks);
        static_cast<MultireweightHistosPTJK*>(mr)->findMaxObservableSusceptibility(betaMax, betaMaxError, suscMax, suscMaxError, susceptibility, v, betaStart, betaEnd);
    }
    HistogramDouble* histo = mr->
            reweightObservableHistogram(betaMax, binCount);
    histo->save(outputDirPrefix + "mrpt-max-susc.hist");
    destroy(histo);

    MetadataMap meta;
    meta["L"] = numToString(mr->systemL);
    meta["N"] = numToString(mr->systemN);
    meta["beta"] = numToString(betaMax, 16);
    meta["susc"] = numToString(suscMax, 16);
    if (use_jackknife) {
        meta["betaError"] = numToString(betaMaxError, 16);
        meta["suscError"] = numToString(suscMaxError, 16);
    }
    string comments = "Maximum of " + mr->observable + " susceptibility, from MRPT\n";
    if (use_jackknife) {
        comments += "Jackknife error estimation, blockCount: "
                + numToString(jackknifeBlocks) + "\n";
    }
    writeOnlyMetaData(outputDirPrefix + "mrpt-max-susc.dat", meta,
            comments);

    writeOutResults();
}

void findMinBinder(double betaStart, double betaEnd) {
    double betaMin;
    double binderMin;
    double betaMinError;
    double binderMinError;
    if (not use_jackknife) {
        mr->findMinBinder(betaMin, binderMin, binder, betaStart, betaEnd);
    } else {
        //TODO: store evaluated points somewhere
        vector<map<double,double> > v(jackknifeBlocks);
        static_cast<MultireweightHistosPTJK*>(mr)->
                findMinBinder(betaMin, betaMinError,
                        binderMin, binderMinError,
                        binder, v, betaStart, betaEnd);
    }
    HistogramDouble* histo = mr->
            reweightObservableHistogram(betaMin, binCount);
    histo->save(outputDirPrefix + "mrpt-min-binder.hist");
    destroy(histo);

    MetadataMap meta;
    meta["L"] = numToString(mr->systemL);
    meta["N"] = numToString(mr->systemN);
    meta["beta"] = numToString(betaMin, 16);
    meta["binder"] = numToString(binderMin, 16);
    if (use_jackknife) {
        meta["betaError"] = numToString(betaMinError, 16);
        meta["binderError"] = numToString(binderMinError, 16);
    }
    string comments = "Minimum of " + mr->observable + " binder cumulant, from MRPT\n";
    if (use_jackknife) {
        comments += "Jackknife error estimation, blockCount: "
                + numToString(jackknifeBlocks) + "\n";
    }
    writeOnlyMetaData(outputDirPrefix + "mrpt-min-binder.dat", meta,
            comments);

    writeOutResults();
}

void findMaxSpecificHeat(double betaStart, double betaEnd) {
    double betaMax;
    double specificHeatMax;
    double betaMaxError;
    double specificHeatMaxError;
    if (not use_jackknife) {
        mr->findMaxSpecificHeatDiscrete(betaMax, specificHeatMax, specificHeat, betaStart, betaEnd);
    } else {
        //TODO: store evaluated points somewhere
        vector<map<double,double> > v(jackknifeBlocks);
        static_cast<MultireweightHistosPTJK*>(mr)->findMaxSpecificHeatDiscrete(betaMax, betaMaxError, specificHeatMax, specificHeatMaxError, specificHeat, v, betaStart, betaEnd);
    }
    HistogramDouble* histo = mr->reweightEnergyHistogram(betaMax);
    histo->save(outputDirPrefix + "mrpt-max-heat-capacity.hist");
    destroy(histo);

    MetadataMap meta;
    meta["L"] = numToString(mr->systemL);
    meta["N"] = numToString(mr->systemN);
    meta["beta"] = numToString(betaMax, 16);
    meta["heatCapacity"] = numToString(specificHeatMax, 16);
    if (use_jackknife) {
        meta["betaError"] = numToString(betaMaxError, 16);
        meta["heatCapacityError"] = numToString(specificHeatMaxError, 16);
    }
    string comments = "Maximum of heat capacity, from MRPT\n";
    if (use_jackknife) {
        comments += "Jackknife error estimation, blockCount: "
                + numToString(jackknifeBlocks) + "\n";
    }
    writeOnlyMetaData(outputDirPrefix + "mrpt-heat-capacity.dat", meta,
            comments);

    writeOutResults();
}

void findEnergyDoublePeak(double betaStart, double betaEnd, double tolerance) {
    double betaDoubleEH;
    double relDipEH;
    double betaDoubleErrorEH;
    double relDipErrorEH;
    HistogramDouble* histoEH = 0;
    double betaDoubleEW;
    double relDipEW;
    double betaDoubleErrorEW;
    double relDipErrorEW;
    HistogramDouble* histoEW = 0;
    if (not use_jackknife) {
        mr->findEnergyEqualHeight(betaDoubleEH, relDipEH, histoEH,
                betaStart, betaEnd, tolerance);
        mr->findEnergyEqualWeight(betaDoubleEW, relDipEW, histoEW,
                histoEH, betaStart, betaEnd, tolerance);
    } else {
        static_cast<MultireweightHistosPTJK*>(mr)->
                findEnergyEqualHeightWeight(betaDoubleEH, betaDoubleErrorEH,
                        relDipEH, relDipErrorEH, histoEH,
                        betaDoubleEW, betaDoubleErrorEW, relDipEW,
                        relDipErrorEW, histoEW,
                        betaStart, betaEnd, tolerance);
    }
    histoEH->save(outputDirPrefix + "mrpt-energy-equal-height.hist");

    MetadataMap metaEH;
    metaEH["observable"] = "energy";
    metaEH["L"] = numToString(mr->systemL);
    metaEH["N"] = numToString(mr->systemN);
    metaEH["beta"] = numToString(betaDoubleEH, 16);
    metaEH["relDip"] = numToString(relDipEH, 16);
    if (use_jackknife) {
        metaEH["betaError"] = numToString(betaDoubleErrorEH, 16);
        metaEH["relDipError"] = numToString(relDipErrorEH, 16);
    }
    string comments = "Location of equal-height double-peak energy histogram, from MRPT\n";
    comments += "relDip is H_max / H_min\n";
    if (use_jackknife) {
        comments += "Jackknife error estimation, blockCount: "
                + numToString(jackknifeBlocks) + "\n";
    }
    writeOnlyMetaData(outputDirPrefix + "mrpt-energy-equal-height.dat", metaEH,
            comments);

    histoEW->save(outputDirPrefix + "mrpt-energy-equal-weight.hist");

    MetadataMap metaEW;
    metaEW["observable"] = "energy";
    metaEW["L"] = numToString(mr->systemL);
    metaEW["N"] = numToString(mr->systemN);
    metaEW["beta"] = numToString(betaDoubleEW, 16);
    metaEW["relDip"] = numToString(relDipEW, 16);
    if (use_jackknife) {
        metaEW["betaError"] = numToString(betaDoubleErrorEW, 16);
        metaEW["relDipError"] = numToString(relDipErrorEW, 16);
    }
    comments = "Location of equal-weight double-peak energy histogram, from MRPT\n";
    comments += "relDip is H_max / H_min\n";
    if (use_jackknife) {
        comments += "Jackknife error estimation, blockCount: "
                + numToString(jackknifeBlocks) + "\n";
    }
    writeOnlyMetaData(outputDirPrefix + "mrpt-energy-equal-weight.dat", metaEW,
            comments);

    destroy(histoEH);
    destroy(histoEW);
}

void findObservableDoublePeak(double betaStart, double betaEnd, double tolerance) {
    double betaDoubleEH;
    double relDipEH;
    double betaDoubleErrorEH;
    double relDipErrorEH;
    HistogramDouble* histoEH = 0;
    double betaDoubleEW;
    double relDipEW;
    double betaDoubleErrorEW;
    double relDipErrorEW;
    HistogramDouble* histoEW = 0;
    if (not use_jackknife) {
        mr->findObsEqualHeight(betaDoubleEH, relDipEH, histoEH,
                betaStart, betaEnd, binCount, tolerance);
        mr->findObsEqualWeight(betaDoubleEW, relDipEW, histoEW,
                histoEH, betaStart, betaEnd, binCount, tolerance);
    } else {
        static_cast<MultireweightHistosPTJK*>(mr)->
                findObservableEqualHeightWeight(
                        betaDoubleEH, betaDoubleErrorEH,
                        relDipEH, relDipErrorEH, histoEH,
                        betaDoubleEW, betaDoubleErrorEW, relDipEW,
                        relDipErrorEW, histoEW,
                        betaStart, betaEnd, binCount, tolerance);
    }
    string obs = mr->observable;

    histoEH->save(outputDirPrefix + "mrpt-" + obs + "-equal-height.hist");

    MetadataMap metaEH;
    metaEH["observable"] = obs;
    metaEH["L"] = numToString(mr->systemL);
    metaEH["N"] = numToString(mr->systemN);
    metaEH["beta"] = numToString(betaDoubleEH, 16);
    metaEH["relDip"] = numToString(relDipEH, 16);
    if (use_jackknife) {
        metaEH["betaError"] = numToString(betaDoubleErrorEH, 16);
        metaEH["relDipError"] = numToString(relDipErrorEH, 16);
    }
    string comments = "Location of equal-height double-peak " +
            obs + " histogram, from MRPT\n";
    comments += "relDip is H_max / H_min\n";
    if (use_jackknife) {
        comments += "Jackknife error estimation, blockCount: "
                + numToString(jackknifeBlocks) + "\n";
    }
    writeOnlyMetaData(outputDirPrefix + "mrpt-" + obs +
            "-equal-height.dat", metaEH, comments);

    histoEW->save(outputDirPrefix + "mrpt-" + obs +
            "-equal-weight.hist");

    MetadataMap metaEW;
    metaEW["observable"] = obs;
    metaEW["L"] = numToString(mr->systemL);
    metaEW["N"] = numToString(mr->systemN);
    metaEW["beta"] = numToString(betaDoubleEW, 16);
    metaEW["relDip"] = numToString(relDipEW, 16);
    if (use_jackknife) {
        metaEW["betaError"] = numToString(betaDoubleErrorEW, 16);
        metaEW["relDipError"] = numToString(relDipErrorEW, 16);
    }
    comments = "Location of equal-weight double-peak " + obs +
            "histogram, from MRPT\n";
    comments += "relDip is H_max / H_min\n";
    if (use_jackknife) {
        comments += "Jackknife error estimation, blockCount: "
                + numToString(jackknifeBlocks) + "\n";
    }
    writeOnlyMetaData(outputDirPrefix + "mrpt-" + obs +
            "-equal-weight.dat", metaEW, comments);

    destroy(histoEH);
    destroy(histoEW);
}


void findEnergyRelDip(double targetBeta, double tolerance) {
    double relDip;
    double relDipError;
    HistogramDouble* histo = 0;
    if (not use_jackknife) {
        mr->energyRelDip(relDip, histo, targetBeta, tolerance);
    } else {
        static_cast<MultireweightHistosPTJK*>(mr)->
                energyRelDip(relDip, relDipError, histo,
                        targetBeta, tolerance);
    }
    string obs = "energy";

    histo->save(outputDirPrefix + "mrpt-" + obs + "-b" +
            numToString(targetBeta) + ".hist");

    MetadataMap meta;
    meta["observable"] = obs;
    meta["L"] = numToString(mr->systemL);
    meta["N"] = numToString(mr->systemN);
    meta["beta"] = numToString(targetBeta, 16);
    meta["relDip"] = numToString(relDip, 16);
    if (use_jackknife) {
        meta["relDipError"] = numToString(relDipError, 16);
    }
    string comments = "relDip is H_max / H_min\n";
    if (use_jackknife) {
        comments += "Jackknife error estimation, blockCount: "
                + numToString(jackknifeBlocks) + "\n";
    }
    writeOnlyMetaData(outputDirPrefix + "mrpt-" + obs +
            "-b" + numToString(targetBeta) +
            "-reldip.dat", meta, comments);

    destroy(histo);
}

void findObservableRelDip(double targetBeta, double tolerance) {
    double relDip;
    double relDipError;
    HistogramDouble* histo = 0;
    if (not use_jackknife) {
        mr->obsRelDip(relDip, histo, targetBeta, binCount, tolerance);
    } else {
        static_cast<MultireweightHistosPTJK*>(mr)->
                obsRelDip(relDip, relDipError,
                        histo, targetBeta, binCount, tolerance);
    }
    string obs = mr->observable;

    histo->save(outputDirPrefix + "mrpt-" + obs + "-b" +
            numToString(targetBeta) + ".hist");

    MetadataMap meta;
    meta["observable"] = obs;
    meta["L"] = numToString(mr->systemL);
    meta["N"] = numToString(mr->systemN);
    meta["beta"] = numToString(targetBeta, 16);
    meta["relDip"] = numToString(relDip, 16);
    if (use_jackknife) {
        meta["relDipError"] = numToString(relDipError, 16);
    }
    string comments = "relDip is H_max / H_min\n";
    if (use_jackknife) {
        comments += "Jackknife error estimation, blockCount: "
                + numToString(jackknifeBlocks) + "\n";
    }
    writeOnlyMetaData(outputDirPrefix + "mrpt-" + obs +
            "-b" + numToString(targetBeta) +
            "-reldip.dat", meta, comments);

    destroy(histo);
}


void getEnergyTimeSeries(unsigned k, int *outN_k, double **outArray1) {
    *outN_k = int(mr->energyTimeSeries[k]->size());
    *outArray1 = mr->energyTimeSeries[k]->data();
}

void getObservableTimeSeries(unsigned k, int *outN_k, double **outArray1) {
    *outN_k = int(mr->observableTimeSeries[k]->size());
    *outArray1 = mr->observableTimeSeries[k]->data();
}

void getBetaIndexTimeSeries(unsigned k, int *outN_k, int **outArray1) {
    *outN_k = int(mr->betaIndexTimeSeries[k]->size());
    *outArray1 = mr->betaIndexTimeSeries[k]->data();
}

void getU_m(int *outM, double **outArray1) {
    *outM = mr->binCount;
    *outArray1 = mr->U_m.data();
}

void getH_km(int *outK, int *outM, int **outArray2) {
    *outK = mr->numReplicas;
    *outM = mr->binCount;
    *outArray2 = mr->H_km.data();
}

void getH_m(int *outM, int **outArray1) {
    *outM = mr->binCount;
    *outArray1 = mr->H_m.data();
}

void getg_km(int *outK, int *outM, double **outArray2) {
    *outK = mr->numReplicas;
    *outM = mr->binCount;
    *outArray2 = mr->g_km.data();
}

void getH_lm(int *outL, int *outM, int **outArray2) {
    *outL = mr->numReplicas;
    *outM = mr->binCount;
    *outArray2 = mr->H_lm.data();
}

void getN_kl(int *outK, int *outL, int **outArray2) {
    *outK = mr->numReplicas;
    *outL = mr->numReplicas;
    *outArray2 = mr->N_kl.data();
}

void getHeff_m(int *outM, double **outArray1) {
    *outM = mr->binCount;
    *outArray1 = mr->Heff_m.data();
}

void getNeff_lm(int *outL, int *outM, double **outArray2) {
    *outL = mr->numReplicas;
    *outM = mr->binCount;
    *outArray2 = mr->Neff_lm.data();
}

void getOriginalBetas(int *outK, double **outArray1) {
    *outK = mr->numReplicas;
    *outArray1 = mr->betas.vec.data();
}

